{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-05T10:17:50.965695Z","iopub.execute_input":"2022-03-05T10:17:50.966155Z","iopub.status.idle":"2022-03-05T10:17:50.99574Z","shell.execute_reply.started":"2022-03-05T10:17:50.966068Z","shell.execute_reply":"2022-03-05T10:17:50.995035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport glob\nimport pathlib\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\nfrom tqdm import tqdm\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:17:50.997263Z","iopub.execute_input":"2022-03-05T10:17:50.997715Z","iopub.status.idle":"2022-03-05T10:17:55.338108Z","shell.execute_reply.started":"2022-03-05T10:17:50.99768Z","shell.execute_reply":"2022-03-05T10:17:55.337361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = '/kaggle/input/data-science-bowl-2018/'\nunzip_base_dir = '/jkaggle/working/'\nstage_train_zip = base_dir + 'stage1_train.zip'\nstage_train_labels_zip = base_dir + 'stage1_train_labels.csv.zip'\nstage_train_unzip = unzip_base_dir + 'stage1_train/'\nstage_train_labels_unzip = unzip_base_dir +'stage1_train_labels/'","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:17:55.339477Z","iopub.execute_input":"2022-03-05T10:17:55.339723Z","iopub.status.idle":"2022-03-05T10:17:55.34506Z","shell.execute_reply.started":"2022-03-05T10:17:55.339691Z","shell.execute_reply":"2022-03-05T10:17:55.344268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nfor path , unzip_path in zip([stage_train_zip,stage_train_labels_zip],[stage_train_unzip,stage_train_labels_unzip]):\n    print(path)\n    print(unzip_path)\n    print('------------')\n    with zipfile.ZipFile(path,'r') as zip_ref:\n        zip_ref.extractall(unzip_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:17:55.347661Z","iopub.execute_input":"2022-03-05T10:17:55.347917Z","iopub.status.idle":"2022-03-05T10:18:01.559357Z","shell.execute_reply.started":"2022-03-05T10:17:55.347884Z","shell.execute_reply":"2022-03-05T10:18:01.558541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = r\"/kaggle/input/data-science-bowl-2018/stage1_test.zip\"\ntest_data_unzip = unzip_base_dir + 'stage1_test/'\nwith zipfile.ZipFile(test_data,'r') as zip_ref:\n    zip_ref.extractall(test_data_unzip)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:01.560455Z","iopub.execute_input":"2022-03-05T10:18:01.560705Z","iopub.status.idle":"2022-03-05T10:18:01.908355Z","shell.execute_reply.started":"2022-03-05T10:18:01.56067Z","shell.execute_reply":"2022-03-05T10:18:01.907653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pathlib.Path(test_data_unzip)\nlsttest_files = glob.glob(str(test/'*/'))\nlsttest_files[:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:01.909568Z","iopub.execute_input":"2022-03-05T10:18:01.910035Z","iopub.status.idle":"2022-03-05T10:18:01.920269Z","shell.execute_reply.started":"2022-03-05T10:18:01.909999Z","shell.execute_reply":"2022-03-05T10:18:01.918331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image(img_path):\n    temp_path = glob.glob(img_path+'/images/*')\n    img = tf.io.read_file(temp_path[0])\n    img = tf.io.decode_image(img)\n    img = tf.image.resize(img, (128,128))\n  \n    arr = img[:, :, :3].numpy()\n    new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min())))\n    return new_arr\n\ntest_images = []\nfor i in lsttest_files:\n    test_images.append(get_image(i))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:01.921608Z","iopub.execute_input":"2022-03-05T10:18:01.921847Z","iopub.status.idle":"2022-03-05T10:18:04.824287Z","shell.execute_reply.started":"2022-03-05T10:18:01.921816Z","shell.execute_reply":"2022-03-05T10:18:04.823526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = tf.convert_to_tensor(np.array(test_images))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:04.82589Z","iopub.execute_input":"2022-03-05T10:18:04.826374Z","iopub.status.idle":"2022-03-05T10:18:04.846444Z","shell.execute_reply.started":"2022-03-05T10:18:04.826336Z","shell.execute_reply":"2022-03-05T10:18:04.845797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.shape(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:04.848952Z","iopub.execute_input":"2022-03-05T10:18:04.849143Z","iopub.status.idle":"2022-03-05T10:18:04.857402Z","shell.execute_reply.started":"2022-03-05T10:18:04.849118Z","shell.execute_reply":"2022-03-05T10:18:04.856591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = pathlib.Path(stage_train_unzip)\nlst_files = glob.glob(str(path/'*/'))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:04.860974Z","iopub.execute_input":"2022-03-05T10:18:04.861155Z","iopub.status.idle":"2022-03-05T10:18:04.869042Z","shell.execute_reply.started":"2022-03-05T10:18:04.861133Z","shell.execute_reply":"2022-03-05T10:18:04.86836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:04.871588Z","iopub.execute_input":"2022-03-05T10:18:04.871779Z","iopub.status.idle":"2022-03-05T10:18:04.877155Z","shell.execute_reply.started":"2022-03-05T10:18:04.871757Z","shell.execute_reply":"2022-03-05T10:18:04.876458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class create_ds(keras.utils.Sequence):\n    def __init__(self,lst_files,batch_size):\n        self.lst_files = lst_files\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return len(self.lst_files)//self.batch_size\n    \n    def get_image(self,image_path):\n        temp_path = glob.glob(image_path+'/images/*')\n        img = tf.io.read_file(temp_path[0])\n        img = tf.io.decode_image(img)\n        img = tf.image.resize(img,(128,128))\n        arr = img[:,:,:3].numpy()\n        new_arr = ((arr-arr.min()))*(1/(arr.max()-arr.min()))\n        \n        ma = glob.glob(image_path+'/masks/*')\n        mask_ = tf.zeros(shape = (128,128,1))\n        \n        \n        for mask_path in ma :\n            mask = tf.io.read_file(mask_path)\n            mask = tf.io.decode_image(mask)\n            mask = tf.image.resize(mask,(128,128))\n            \n            mask_ = tf.maximum(mask_,mask)\n        return new_arr,mask_.numpy()    \n    def __getitem__(self,idx):\n        batch = self.lst_files[idx*self.batch_size : (idx+1)*self.batch_size ]\n        \n        temp_image = []\n        temp_label = []\n        for path in batch :\n            new_arr , mask = self.get_image(path)\n            temp_image.append(new_arr)\n            temp_label.append(mask/255.0)\n        return tf.convert_to_tensor(np.array(temp_image),dtype = 'float32'), tf.convert_to_tensor(np.array(temp_label),dtype = 'float32')   ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:04.878039Z","iopub.execute_input":"2022-03-05T10:18:04.878227Z","iopub.status.idle":"2022-03-05T10:18:05.705178Z","shell.execute_reply.started":"2022-03-05T10:18:04.8782Z","shell.execute_reply":"2022-03-05T10:18:05.704455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\ndef plot_train_valid_curve(df):\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=list(range(len(df))),y=df['loss'],mode='lines',name = 'Train_loss'))\n    \n    fig.add_trace(go.Scatter(x=list(range(len(df))),y = df['val_loss'],mode ='lines',name = 'val_loss'))\n    \n    fig.add_trace(go.Scatter(x=list(range(len(df))),y = df['accuracy'],mode='lines',name = 'Train_accuracy'))\n    \n    fig.add_trace(go.Scatter(x=list(range(len(df))),y = df['val_accuracy'],mode='lines',name = 'val_accuracy'))\n    \n    fig.show()\n    \ndef plot_predicted(x_test,valid,pred):\n        fig = plt.figure(figsize=(15,7))\n        plt.subplot(1,3,1)\n        plt.title('Actual Image')\n        plt.imshow(x_test)\n        \n        plt.subplot(1,3,2)\n        plt.title('Actual mask')\n        plt.imshow(valid)\n        \n        plt.subplot(1,3,3)\n        plt.title('Predicted mask')\n        plt.imshow(pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:05.706482Z","iopub.execute_input":"2022-03-05T10:18:05.706733Z","iopub.status.idle":"2022-03-05T10:18:05.725293Z","shell.execute_reply.started":"2022-03-05T10:18:05.706701Z","shell.execute_reply":"2022-03-05T10:18:05.724493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, valid = train_test_split(lst_files)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:05.726369Z","iopub.execute_input":"2022-03-05T10:18:05.726796Z","iopub.status.idle":"2022-03-05T10:18:06.295627Z","shell.execute_reply.started":"2022-03-05T10:18:05.726759Z","shell.execute_reply":"2022-03-05T10:18:06.294924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train))\nprint(len(valid))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:06.297026Z","iopub.execute_input":"2022-03-05T10:18:06.297288Z","iopub.status.idle":"2022-03-05T10:18:06.302582Z","shell.execute_reply.started":"2022-03-05T10:18:06.297255Z","shell.execute_reply":"2022-03-05T10:18:06.301847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating training and validation datasets","metadata":{}},{"cell_type":"code","source":"train_ds = create_ds(lst_files=train, batch_size = BATCH_SIZE) \nvalid_ds= create_ds(lst_files=valid, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:06.303981Z","iopub.execute_input":"2022-03-05T10:18:06.304516Z","iopub.status.idle":"2022-03-05T10:18:06.310597Z","shell.execute_reply.started":"2022-03-05T10:18:06.30448Z","shell.execute_reply":"2022-03-05T10:18:06.309831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 128\nIMAGE_WIDTH = 128\nCHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:06.312225Z","iopub.execute_input":"2022-03-05T10:18:06.312469Z","iopub.status.idle":"2022-03-05T10:18:06.318928Z","shell.execute_reply.started":"2022-03-05T10:18:06.312438Z","shell.execute_reply":"2022-03-05T10:18:06.318094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Defining the model","metadata":{}},{"cell_type":"code","source":"def Unet(IMAGE_HEIGHT , IMAGE_WIDTH,CHANNEL):\n    inputs = keras.Input(shape = (IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL))\n    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(inputs)\n    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_1)\n    # conv_1\n\n    conv_2 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_1)\n    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n\n    conv_3 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_2)\n    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n\n    conv_4 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_3)\n    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n\n    conv_5 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_4)\n    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n    \n    conv_6 = keras.layers.Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding='same')(conv_5)\n    conv_6 = keras.layers.concatenate([conv_4, conv_6])\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n    \n    conv_6 = keras.layers.Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding='same')(conv_5)\n    conv_6 = keras.layers.concatenate([conv_4, conv_6])\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n\n    conv_7 = keras.layers.Conv2DTranspose(filters = 64, kernel_size = 2, strides = 2, padding='same')(conv_6)\n    conv_7 = keras.layers.concatenate([conv_3, conv_7])\n    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n\n    conv_8 = keras.layers.Conv2DTranspose(filters = 32, kernel_size = 2, strides = 2, padding='same')(conv_7)\n    conv_8 = keras.layers.concatenate([conv_2, conv_8])\n    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n\n\n    conv_9 = keras.layers.Conv2DTranspose(filters = 16, kernel_size = 2, strides = 2, padding='same')(conv_8)\n    conv_9 = keras.layers.concatenate([conv_1, conv_9])\n    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n\n    output = keras.layers.Conv2D(filters = 1, kernel_size = 3, padding='same', activation='relu')(conv_9)\n    model = keras.Model(inputs, output)\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:06.320186Z","iopub.execute_input":"2022-03-05T10:18:06.32049Z","iopub.status.idle":"2022-03-05T10:18:06.343049Z","shell.execute_reply.started":"2022-03-05T10:18:06.320394Z","shell.execute_reply":"2022-03-05T10:18:06.342323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Unet(IMAGE_HEIGHT , IMAGE_WIDTH , CHANNELS)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:06.344258Z","iopub.execute_input":"2022-03-05T10:18:06.344666Z","iopub.status.idle":"2022-03-05T10:18:06.621284Z","shell.execute_reply.started":"2022-03-05T10:18:06.344617Z","shell.execute_reply":"2022-03-05T10:18:06.620621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_slices = []\ny_train_slices = []\n\nx_test_slices = []\ny_test_slices = []\n\nfor(train,train_label) in tqdm(train_ds):\n    for x_train,y_train in zip(train,train_label):\n        x_train_slices.append(x_train.numpy())\n        y_train_slices.append(y_train.numpy())\n        \nfor (valid,valid_label) in tqdm(valid_ds):\n    for x_test , y_test in zip(valid,valid_label):\n        \n        x_test_slices.append(x_test.numpy())\n        y_test_slices.append(y_test.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:06.622755Z","iopub.execute_input":"2022-03-05T10:18:06.623009Z","iopub.status.idle":"2022-03-05T10:18:59.030353Z","shell.execute_reply.started":"2022-03-05T10:18:06.622975Z","shell.execute_reply":"2022-03-05T10:18:59.028922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tensor_ds = tf.data.Dataset.from_tensor_slices((x_train_slices, y_train_slices))\nvalid_tensor_ds = tf.data.Dataset.from_tensor_slices((x_test_slices, y_test_slices))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:18:59.031688Z","iopub.execute_input":"2022-03-05T10:18:59.032099Z","iopub.status.idle":"2022-03-05T10:19:30.848324Z","shell.execute_reply.started":"2022-03-05T10:18:59.032059Z","shell.execute_reply":"2022-03-05T10:19:30.847589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\ntrain_tensor_ds = train_tensor_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\nvalid_tensor_ds = valid_tensor_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:19:30.849589Z","iopub.execute_input":"2022-03-05T10:19:30.849838Z","iopub.status.idle":"2022-03-05T10:19:30.862417Z","shell.execute_reply.started":"2022-03-05T10:19:30.849804Z","shell.execute_reply":"2022-03-05T10:19:30.8617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scheduler(epoch):\n    if epoch <50:\n        return 0.001\n    \n    elif (50<= epoch and epoch <=70 ):\n        return 0.0001\n    \n    elif (epoch>70):\n        return 0.0001 \ncall_back = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:19:30.86392Z","iopub.execute_input":"2022-03-05T10:19:30.864173Z","iopub.status.idle":"2022-03-05T10:19:30.876706Z","shell.execute_reply.started":"2022-03-05T10:19:30.864131Z","shell.execute_reply":"2022-03-05T10:19:30.876039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Unet(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n\nstart = time.time()\n\nhistory = model.fit(train_tensor_ds, validation_data = valid_tensor_ds, epochs = 100, callbacks = [call_back], verbose=False)\n\nend = time.time()\n\nprint(f'Time required for the execution is {end - start}')\n\nmodel.save_weights('./weights')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:19:30.877743Z","iopub.execute_input":"2022-03-05T10:19:30.878034Z","iopub.status.idle":"2022-03-05T10:20:50.963306Z","shell.execute_reply.started":"2022-03-05T10:19:30.877998Z","shell.execute_reply":"2022-03-05T10:20:50.961859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(history.history)\nplot_train_valid_curve(df1)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:20:50.964513Z","iopub.execute_input":"2022-03-05T10:20:50.96478Z","iopub.status.idle":"2022-03-05T10:20:51.074121Z","shell.execute_reply.started":"2022-03-05T10:20:50.964744Z","shell.execute_reply":"2022-03-05T10:20:51.073489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(np.array(x_test_slices))\npred_t = (pred >0.5).astype('uint8')\n\nfor plot_image in range(3):\n    random_image = np.random.randint(0, len(x_test_slices))\n    plot_predicted(np.array(x_test_slices)[random_image], np.array(y_test_slices)[random_image],  pred_t[random_image])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T10:20:51.075366Z","iopub.execute_input":"2022-03-05T10:20:51.075597Z","iopub.status.idle":"2022-03-05T10:20:53.186892Z","shell.execute_reply.started":"2022-03-05T10:20:51.075564Z","shell.execute_reply":"2022-03-05T10:20:53.186177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}